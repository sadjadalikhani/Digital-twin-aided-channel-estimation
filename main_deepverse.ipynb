{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Twin-Aided Channel Estimation\n",
    "\n",
    "Effective channel estimation in sparse and high-dimensional environments is essential for next-generation wireless systems, particularly in large-scale MIMO deployments. This paper introduces a novel framework that leverages digital twins (DTs) as priors to enable efficient zone-specific subspace-based channel estimation (CE). Subspace-based CE significantly reduces feedback overhead by focusing on the dominant channel components, exploiting sparsity in the angular domain while preserving estimation accuracy. While DT channels may exhibit inaccuracies, their coarse-grained subspaces provide a powerful starting point, reducing the search space and accelerating convergence. The framework employs a two-step clustering process on the Grassmann manifold, combined with reinforcement learning (RL), to iteratively calibrate subspaces and align them with realworld counterparts. Simulations show that digital twins not only enable near-optimal performance but also enhance the accuracy of subspace calibration through RL, highlighting their potential as a step towards learnable digital twins.\n",
    "\n",
    "\n",
    "## System Overview\n",
    "\n",
    "The following figures illustrate the key concepts and system model used in this work:\n",
    "\n",
    "### System Model\n",
    "<img src=\"figs/deepmimo/system_model.PNG\" alt=\"System Model\" width=\"1300\">\n",
    "\n",
    "The figure illustrates the proposed zone-specific subspace prediction and calibration framework for channel estimation using digital twins. The BS designs precoders for each zone, enabling UEs to estimate the projection of real-world channels onto low-dimensional DT-based subspaces. Zones are defined by user subspace similarities on the Grassmann manifold. This approach significantly reduces CSI feedback overhead by leveraging channel sparsity and DT-based subspace detection. To address DT approximation errors, subspaces are further calibrated to optimize overhead and estimation accuracy\n",
    "\n",
    "### Calibration Idea\n",
    "<img src='figs/deepmimo/calibration_idea.png' alt=\"Calibration Idea\" width=\"1000\">\n",
    "\n",
    "This figure demonstrates the calibration approach used to improve digital twin performance through reinforcement learning-based optimization.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Imports](#imports)\n",
    "2. [Utility Functions](#utility-functions)\n",
    "3. [DRL Components](#drl-components)\n",
    "4. [Plotting Functions](#plotting-functions)\n",
    "5. [Main Experiments](#main-experiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Digital-twin-aided-channel-estimation'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sadjadalikhani/Digital-twin-aided-channel-estimation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g:\\Sadjad\\Git\\Digital-twin-aided-channel-estimation\\Digital-twin-aided-channel-estimation\n"
     ]
    }
   ],
   "source": [
    "cd Digital-twin-aided-channel-estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive G is Elements\n",
      " Volume Serial Number is B822-6E6D\n",
      "\n",
      " Directory of g:\\Sadjad\\Git\\Digital-twin-aided-channel-estimation\\Digital-twin-aided-channel-estimation\n",
      "\n",
      "10/26/2025  02:47 PM    <DIR>          .\n",
      "10/26/2025  02:47 PM    <DIR>          ..\n",
      "10/26/2025  02:46 PM                68 .gitattributes\n",
      "10/26/2025  02:46 PM                41 .gitignore\n",
      "10/26/2025  02:47 PM    <DIR>          __pycache__\n",
      "10/26/2025  02:46 PM    <DIR>          deepverse_utils\n",
      "10/26/2025  02:46 PM    <DIR>          figs\n",
      "10/26/2025  02:46 PM            11,146 input_preprocess.py\n",
      "10/26/2025  02:46 PM             7,352 main.py\n",
      "10/26/2025  02:46 PM            17,875 main_deepverse.ipynb\n",
      "10/26/2025  02:46 PM             8,260 main_deepverse.py\n",
      "10/26/2025  02:46 PM             7,661 README.md\n",
      "10/26/2025  02:48 PM    <DIR>          scenarios\n",
      "10/26/2025  02:46 PM            34,562 utils.py\n",
      "10/26/2025  02:46 PM    <DIR>          variables\n",
      "               8 File(s)         86,965 bytes\n",
      "               7 Dir(s)  304,251,715,584 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import k_means, k_med, subspace_estimation, todB, subspace_estimation_drl, generate_dft_codebook, plot_smooth_cdf, plot_perf_vs_pilots\n",
    "import matplotlib.cm as cm\n",
    "import zipfile\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepVerse Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing wireless data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: wireless.zip: 100%|██████████| 3.77G/3.77G [01:57<00:00, 34.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infalting: scenarios\\Carla-Town05\\wireless.zip\n",
      "Removing zip: scenarios\\Carla-Town05\\wireless.zip\n",
      "Preparing parameter files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: param.zip: 100%|██████████| 87.1M/87.1M [00:01<00:00, 62.7MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infalting: scenarios\\Carla-Town05\\param.zip\n",
      "Removing zip: scenarios\\Carla-Town05\\param.zip\n",
      "DeepVerse scenario Carla-Town05 is ready!\n"
     ]
    }
   ],
   "source": [
    "def download_and_unzip(url, zip_path, extract_to):\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    total = int(response.headers.get('content-length', 0))\n",
    "    with open(zip_path, 'wb') as f, tqdm(\n",
    "        desc=f\"Downloading: {zip_path.name}\",\n",
    "        total=total,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            size = f.write(chunk)\n",
    "            bar.update(size)\n",
    "\n",
    "    print(f\"Infalting: {zip_path}\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: {zip_path} is not a valid zip file!\")\n",
    "        return\n",
    "\n",
    "    print(f\"Removing zip: {zip_path}\")\n",
    "    zip_path.unlink()\n",
    "\n",
    "# Set up directories\n",
    "scenario_name = 'Carla-Town05'\n",
    "scenario_dir = Path(f\"scenarios/{scenario_name}\")\n",
    "scenario_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and extract wireless data\n",
    "print(\"Preparing wireless data...\")\n",
    "download_and_unzip(\n",
    "    \"https://www.dropbox.com/scl/fi/xz9yg0zgx7r4scfc1747f/wireless.zip?rlkey=iigyjagh6irxeu5mp14zq8tz9&e=1&st=r32fwt57&dl=1\",\n",
    "    scenario_dir / \"wireless.zip\",\n",
    "    scenario_dir\n",
    ")\n",
    "\n",
    "# Download and extract parameter files\n",
    "print(\"Preparing parameter files...\")\n",
    "param_dir = scenario_dir / \"param\"\n",
    "param_dir.mkdir(parents=True, exist_ok=True)\n",
    "download_and_unzip(\n",
    "    \"https://www.dropbox.com/scl/fo/9qpcn5apzn4anj5xbdpcs/ANZ4uT6LFow_Dd2-vuSY66s?rlkey=3bgref7fdnc53j2i5r7vsd7eo&e=1&st=srhylwot&dl=1\",\n",
    "    scenario_dir / \"param.zip\",\n",
    "    param_dir\n",
    ")\n",
    "\n",
    "# Copy wireless params.mat file to wireless folder\n",
    "wireless_dir = scenario_dir / \"wireless\"\n",
    "shutil.copy(param_dir / \"params.mat\", wireless_dir / \"params.mat\")\n",
    "\n",
    "print(f\"DeepVerse scenario {scenario_name} is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digital Twin and Real-World Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Digital Twin and Real-World Channel Generation ===\n",
      "Scenarios: [0 1 2 3 4 5 6 7 8 9]\n",
      "Number of beams: 128\n",
      "Paths - Digital Twin: 5, Real-World: 25\n",
      "\n",
      "=== Configuring Digital Twin Dataset ===\n",
      "Loaded parameters for 10 scenes with 5 paths each\n",
      "Scenes: [0 1 2 3 4 5 6 7 8 9]\n",
      "Communication enabled: True\n",
      "Doppler effects enabled: False\n",
      "Generating dataset...\n",
      "Warning: scenarios\\Carla-Town05\\RGB_images does not exist.\n",
      "Warning: scenarios\\Carla-Town05\\lidar does not exist.\n",
      "Generating comm dataset: ⏳ In progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[F\u001b[KGenerating comm dataset: ✅ Completed (0.54s)\n",
      "Dataset generation completed!\n",
      "\n",
      "=== Configuring Real-World Dataset ===\n",
      "Loaded parameters for 10 scenes with 25 paths each\n",
      "Scenes: [0 1 2 3 4 5 6 7 8 9]\n",
      "Communication enabled: True\n",
      "Doppler effects enabled: True\n",
      "Generating dataset...\n",
      "Warning: scenarios\\Carla-Town05\\RGB_images does not exist.\n",
      "Warning: scenarios\\Carla-Town05\\lidar does not exist.\n",
      "Generating comm dataset: ⏳ In progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[F\u001b[KGenerating comm dataset: ✅ Completed (0.51s)\n",
      "Dataset generation completed!\n",
      "\n",
      "=== Generating Overlayed Users ===\n",
      "Overlaying users from 10 scenes...\n",
      "Warning: Could not load user 7 from scene 0: list index out of range\n",
      "Warning: Could not load user 7 from scene 1: list index out of range\n",
      "Warning: Could not load user 7 from scene 2: list index out of range\n",
      "Warning: Could not load user 7 from scene 3: list index out of range\n",
      "Warning: Could not load user 7 from scene 4: list index out of range\n",
      "Warning: Could not load user 7 from scene 5: list index out of range\n",
      "Warning: Could not load user 7 from scene 6: list index out of range\n",
      "Warning: Could not load user 7 from scene 7: list index out of range\n",
      "Warning: Could not load user 7 from scene 8: list index out of range\n",
      "Warning: Could not load user 7 from scene 9: list index out of range\n",
      "Successfully overlayed 70 users from 10 scenes\n",
      "\n",
      "=== Processing Channel Data ===\n",
      "Warning: Could not process RW user 0: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 1: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 2: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 3: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 4: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 5: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 6: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 7: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 8: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 9: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 10: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 11: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 12: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 13: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 14: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 15: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 16: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 17: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 18: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 19: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 20: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 21: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 22: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 23: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 24: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 25: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 26: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 27: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 28: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 29: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 30: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 31: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 32: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 33: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 34: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 35: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 36: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 37: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 38: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 39: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 40: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 41: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 42: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 43: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 44: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 45: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 46: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 47: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 48: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 49: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 50: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 51: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 52: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 53: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 54: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 55: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 56: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 57: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 58: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 59: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 60: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 61: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 62: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 63: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 64: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 65: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 66: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 67: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 68: cannot select an axis to squeeze out which has size not equal to one\n",
      "Warning: Could not process RW user 69: cannot select an axis to squeeze out which has size not equal to one\n",
      "Generating 0 corresponding Digital Twin channels...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 0 is different from 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m M_y = n_beams // M_x\n\u001b[32m     10\u001b[39m codebook = generate_dft_codebook(M_x, M_y) \n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m dataset_dt, dataset_rw, pos, los_status, best_beam, enabled_idxs, bs_pos = chs_gen(\n\u001b[32m     13\u001b[39m     scenarios,\n\u001b[32m     14\u001b[39m     n_beams, \n\u001b[32m     15\u001b[39m     fov,\n\u001b[32m     16\u001b[39m     n_path,\n\u001b[32m     17\u001b[39m     codebook)\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# Keep as PyTorch tensors for k_means function compatibility\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# dataset_dt and dataset_rw are already PyTorch tensors from chs_gen\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Ensure all arrays have correct dimensions for k_means function\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# pos should be (N, 3), los_status and best_beam should be (N, 1) for concatenation\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(los_status.shape) == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Sadjad\\Git\\Digital-twin-aided-channel-estimation\\Digital-twin-aided-channel-estimation\\deepverse_utils\\deepverse_dt_rw_channel_gen.py:177\u001b[39m, in \u001b[36mchs_gen\u001b[39m\u001b[34m(scenarios, n_beams, fov, n_path, codebook)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# Calculate best beam indices using beam steering\u001b[39;00m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m codebook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     best_beam = calculate_best_beams(dataset_rw, codebook)\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# Generate default codebook if none provided\u001b[39;00m\n\u001b[32m    180\u001b[39m     codebook = generate_default_codebook(n_beams)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Sadjad\\Git\\Digital-twin-aided-channel-estimation\\Digital-twin-aided-channel-estimation\\deepverse_utils\\deepverse_dt_rw_channel_gen.py:239\u001b[39m, in \u001b[36mcalculate_best_beams\u001b[39m\u001b[34m(channels, codebook)\u001b[39m\n\u001b[32m    236\u001b[39m channels_np = channels.numpy()\n\u001b[32m    238\u001b[39m \u001b[38;5;66;03m# Calculate beam power for each channel\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m beam_power = np.abs(codebook @ channels_np.T)**\u001b[32m2\u001b[39m  \u001b[38;5;66;03m# (n_beams, N)\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;66;03m# Find best beam for each channel\u001b[39;00m\n\u001b[32m    242\u001b[39m best_beam = np.argmax(beam_power, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 0 is different from 128)"
     ]
    }
   ],
   "source": [
    "from deepverse_utils.deepverse_dt_rw_channel_gen import chs_gen\n",
    "\n",
    "scenarios = np.arange(10)  # Use first 4000 scenes from Carla-Town05\n",
    "n_beams = 128 \n",
    "fov = 180\n",
    "n_path = [5, 25]  # [Digital Twin paths, Real-World paths]\n",
    "\n",
    "M_x = 1\n",
    "M_y = n_beams // M_x\n",
    "codebook = generate_dft_codebook(M_x, M_y) \n",
    "\n",
    "dataset_dt, dataset_rw, pos, los_status, best_beam, enabled_idxs, bs_pos = chs_gen(\n",
    "    scenarios,\n",
    "    n_beams, \n",
    "    fov,\n",
    "    n_path,\n",
    "    codebook)\n",
    "\n",
    "    # Keep as PyTorch tensors for k_means function compatibility\n",
    "    # dataset_dt and dataset_rw are already PyTorch tensors from chs_gen\n",
    "\n",
    "# Ensure all arrays have correct dimensions for k_means function\n",
    "# pos should be (N, 3), los_status and best_beam should be (N, 1) for concatenation\n",
    "if len(los_status.shape) == 1:\n",
    "    los_status = los_status.reshape(-1, 1)\n",
    "if len(best_beam.shape) == 1:\n",
    "    best_beam = best_beam.reshape(-1, 1)\n",
    "\n",
    "print(f\"\\n=== Dataset Information ===\")\n",
    "print(f\"Digital Twin dataset shape: {dataset_dt.shape}\")\n",
    "print(f\"Real-World dataset shape: {dataset_rw.shape}\")\n",
    "print(f\"User positions shape: {pos.shape}\")\n",
    "print(f\"LoS status shape: {los_status.shape}\")\n",
    "print(f\"Best beam indices shape: {best_beam.shape}\")\n",
    "print(f\"Enabled user indices: {len(enabled_idxs)}\")\n",
    "print(f\"Base station position: {bs_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(dataset_dt)\n",
    "pos_coeff = 1\n",
    "los_coeff_kmeans = 0\n",
    "beam_coeff_kmeans = 0 \n",
    "umap_coeff = 0\n",
    "subspace_coeff = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 2: Channel Reconstruction Performance VS Number of Pilots Plot (No calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "trial: 0\n",
      "dataset type: Real-World\n",
      "Number of users: 70\n",
      "Adjusted parameters: n_areas=12, n_kmeans_clusters=35\n",
      "Areas have min 1 idxs, max 10 idxs, and an avg of 5.833333333333333 idxs.\n",
      "zone id: 0, n_pilots: 1, perf: 0.604\n",
      "zone id: 0, n_pilots: 13, perf: 0.936\n",
      "zone id: 0, n_pilots: 26, perf: 0.945\n",
      "zone id: 0, n_pilots: 38, perf: 0.948\n",
      "zone id: 0, n_pilots: 51, perf: 0.950\n",
      "zone id: 0, n_pilots: 64, perf: 0.951\n",
      "zone id: 0, n_pilots: 77, perf: 0.950\n",
      "zone id: 0, n_pilots: 90, perf: 0.954\n",
      "zone id: 0, n_pilots: 102, perf: 0.953\n",
      "zone id: 0, n_pilots: 115, perf: 0.955\n",
      "zone id: 0, n_pilots: 128, perf: 0.953\n",
      "zone id: 1, n_pilots: 1, perf: 0.929\n",
      "zone id: 1, n_pilots: 13, perf: 0.956\n",
      "zone id: 1, n_pilots: 26, perf: 0.955\n",
      "zone id: 1, n_pilots: 38, perf: 0.952\n",
      "zone id: 1, n_pilots: 51, perf: 0.951\n",
      "zone id: 1, n_pilots: 64, perf: 0.956\n",
      "zone id: 1, n_pilots: 77, perf: 0.953\n",
      "zone id: 1, n_pilots: 90, perf: 0.952\n",
      "zone id: 1, n_pilots: 102, perf: 0.955\n",
      "zone id: 1, n_pilots: 115, perf: 0.953\n",
      "zone id: 1, n_pilots: 128, perf: 0.952\n",
      "zone id: 2, n_pilots: 1, perf: 0.964\n",
      "zone id: 2, n_pilots: 13, perf: 0.952\n",
      "zone id: 2, n_pilots: 26, perf: 0.952\n",
      "zone id: 2, n_pilots: 38, perf: 0.953\n",
      "zone id: 2, n_pilots: 51, perf: 0.954\n",
      "zone id: 2, n_pilots: 64, perf: 0.952\n",
      "zone id: 2, n_pilots: 77, perf: 0.956\n",
      "zone id: 2, n_pilots: 90, perf: 0.952\n",
      "zone id: 2, n_pilots: 102, perf: 0.953\n",
      "zone id: 2, n_pilots: 115, perf: 0.955\n",
      "zone id: 2, n_pilots: 128, perf: 0.952\n",
      "zone id: 3, n_pilots: 1, perf: 0.933\n",
      "zone id: 3, n_pilots: 13, perf: 0.952\n",
      "zone id: 3, n_pilots: 26, perf: 0.950\n",
      "zone id: 3, n_pilots: 38, perf: 0.954\n",
      "zone id: 3, n_pilots: 51, perf: 0.955\n",
      "zone id: 3, n_pilots: 64, perf: 0.953\n",
      "zone id: 3, n_pilots: 77, perf: 0.953\n",
      "zone id: 3, n_pilots: 90, perf: 0.954\n",
      "zone id: 3, n_pilots: 102, perf: 0.953\n",
      "zone id: 3, n_pilots: 115, perf: 0.954\n",
      "zone id: 3, n_pilots: 128, perf: 0.954\n",
      "zone id: 4, n_pilots: 1, perf: 0.906\n",
      "zone id: 4, n_pilots: 13, perf: 0.954\n",
      "zone id: 4, n_pilots: 26, perf: 0.956\n",
      "zone id: 4, n_pilots: 38, perf: 0.953\n",
      "zone id: 4, n_pilots: 51, perf: 0.953\n",
      "zone id: 4, n_pilots: 64, perf: 0.952\n",
      "zone id: 4, n_pilots: 77, perf: 0.954\n",
      "zone id: 4, n_pilots: 90, perf: 0.952\n",
      "zone id: 4, n_pilots: 102, perf: 0.954\n",
      "zone id: 4, n_pilots: 115, perf: 0.953\n",
      "zone id: 4, n_pilots: 128, perf: 0.954\n",
      "zone id: 5, n_pilots: 1, perf: 0.609\n",
      "zone id: 5, n_pilots: 13, perf: 0.931\n",
      "zone id: 5, n_pilots: 26, perf: 0.945\n",
      "zone id: 5, n_pilots: 38, perf: 0.949\n",
      "zone id: 5, n_pilots: 51, perf: 0.950\n",
      "zone id: 5, n_pilots: 64, perf: 0.951\n",
      "zone id: 5, n_pilots: 77, perf: 0.952\n",
      "zone id: 5, n_pilots: 90, perf: 0.952\n",
      "zone id: 5, n_pilots: 102, perf: 0.954\n",
      "zone id: 5, n_pilots: 115, perf: 0.954\n",
      "zone id: 5, n_pilots: 128, perf: 0.954\n",
      "zone id: 6, n_pilots: 1, perf: 0.702\n",
      "zone id: 6, n_pilots: 13, perf: 0.938\n",
      "zone id: 6, n_pilots: 26, perf: 0.942\n",
      "zone id: 6, n_pilots: 38, perf: 0.951\n",
      "zone id: 6, n_pilots: 51, perf: 0.948\n",
      "zone id: 6, n_pilots: 64, perf: 0.951\n",
      "zone id: 6, n_pilots: 77, perf: 0.951\n",
      "zone id: 6, n_pilots: 90, perf: 0.952\n",
      "zone id: 6, n_pilots: 102, perf: 0.954\n",
      "zone id: 6, n_pilots: 115, perf: 0.953\n",
      "zone id: 6, n_pilots: 128, perf: 0.954\n",
      "zone id: 7, n_pilots: 1, perf: 0.237\n",
      "zone id: 7, n_pilots: 13, perf: 0.936\n",
      "zone id: 7, n_pilots: 26, perf: 0.945\n",
      "zone id: 7, n_pilots: 38, perf: 0.950\n",
      "zone id: 7, n_pilots: 51, perf: 0.950\n",
      "zone id: 7, n_pilots: 64, perf: 0.952\n",
      "zone id: 7, n_pilots: 77, perf: 0.954\n",
      "zone id: 7, n_pilots: 90, perf: 0.953\n",
      "zone id: 7, n_pilots: 102, perf: 0.954\n",
      "zone id: 7, n_pilots: 115, perf: 0.954\n",
      "zone id: 7, n_pilots: 128, perf: 0.952\n",
      "zone id: 8, n_pilots: 1, perf: 0.900\n",
      "zone id: 8, n_pilots: 13, perf: 0.935\n",
      "zone id: 8, n_pilots: 26, perf: 0.940\n",
      "zone id: 8, n_pilots: 38, perf: 0.953\n",
      "zone id: 8, n_pilots: 51, perf: 0.953\n",
      "zone id: 8, n_pilots: 64, perf: 0.953\n",
      "zone id: 8, n_pilots: 77, perf: 0.953\n",
      "zone id: 8, n_pilots: 90, perf: 0.955\n",
      "zone id: 8, n_pilots: 102, perf: 0.953\n",
      "zone id: 8, n_pilots: 115, perf: 0.952\n",
      "zone id: 8, n_pilots: 128, perf: 0.955\n",
      "zone id: 9, n_pilots: 1, perf: 0.533\n",
      "zone id: 9, n_pilots: 13, perf: 0.888\n",
      "zone id: 9, n_pilots: 26, perf: 0.925\n",
      "zone id: 9, n_pilots: 38, perf: 0.944\n",
      "zone id: 9, n_pilots: 51, perf: 0.951\n",
      "zone id: 9, n_pilots: 64, perf: 0.952\n",
      "zone id: 9, n_pilots: 77, perf: 0.953\n",
      "zone id: 9, n_pilots: 90, perf: 0.954\n",
      "zone id: 9, n_pilots: 102, perf: 0.954\n",
      "zone id: 9, n_pilots: 115, perf: 0.953\n",
      "zone id: 9, n_pilots: 128, perf: 0.955\n",
      "zone id: 10, n_pilots: 1, perf: 0.746\n",
      "zone id: 10, n_pilots: 13, perf: 0.929\n",
      "zone id: 10, n_pilots: 26, perf: 0.945\n",
      "zone id: 10, n_pilots: 38, perf: 0.948\n",
      "zone id: 10, n_pilots: 51, perf: 0.949\n",
      "zone id: 10, n_pilots: 64, perf: 0.952\n",
      "zone id: 10, n_pilots: 77, perf: 0.951\n",
      "zone id: 10, n_pilots: 90, perf: 0.954\n",
      "zone id: 10, n_pilots: 102, perf: 0.954\n",
      "zone id: 10, n_pilots: 115, perf: 0.953\n",
      "zone id: 10, n_pilots: 128, perf: 0.953\n",
      "zone id: 11, n_pilots: 1, perf: 0.887\n",
      "zone id: 11, n_pilots: 13, perf: 0.944\n",
      "zone id: 11, n_pilots: 26, perf: 0.949\n",
      "zone id: 11, n_pilots: 38, perf: 0.950\n",
      "zone id: 11, n_pilots: 51, perf: 0.952\n",
      "zone id: 11, n_pilots: 64, perf: 0.951\n",
      "zone id: 11, n_pilots: 77, perf: 0.954\n",
      "zone id: 11, n_pilots: 90, perf: 0.953\n",
      "zone id: 11, n_pilots: 102, perf: 0.952\n",
      "zone id: 11, n_pilots: 115, perf: 0.954\n",
      "zone id: 11, n_pilots: 128, perf: 0.954\n",
      "\n",
      "\n",
      "trial: 0\n",
      "dataset type: Digital Twin\n",
      "Number of users: 70\n",
      "Adjusted parameters: n_areas=12, n_kmeans_clusters=35\n",
      "zone id: 0, n_pilots: 1, perf: 0.045\n",
      "zone id: 0, n_pilots: 13, perf: 0.929\n",
      "zone id: 0, n_pilots: 26, perf: 0.941\n",
      "zone id: 0, n_pilots: 38, perf: 0.940\n",
      "zone id: 0, n_pilots: 51, perf: 0.943\n",
      "zone id: 0, n_pilots: 64, perf: 0.943\n",
      "zone id: 0, n_pilots: 77, perf: 0.943\n",
      "zone id: 0, n_pilots: 90, perf: 0.944\n",
      "zone id: 0, n_pilots: 102, perf: 0.945\n",
      "zone id: 0, n_pilots: 115, perf: 0.945\n",
      "zone id: 0, n_pilots: 128, perf: 0.954\n",
      "zone id: 1, n_pilots: 1, perf: 0.010\n",
      "zone id: 1, n_pilots: 13, perf: 0.943\n",
      "zone id: 1, n_pilots: 26, perf: 0.939\n",
      "zone id: 1, n_pilots: 38, perf: 0.937\n",
      "zone id: 1, n_pilots: 51, perf: 0.940\n",
      "zone id: 1, n_pilots: 64, perf: 0.943\n",
      "zone id: 1, n_pilots: 77, perf: 0.943\n",
      "zone id: 1, n_pilots: 90, perf: 0.945\n",
      "zone id: 1, n_pilots: 102, perf: 0.946\n",
      "zone id: 1, n_pilots: 115, perf: 0.946\n",
      "zone id: 1, n_pilots: 128, perf: 0.953\n",
      "zone id: 2, n_pilots: 1, perf: 0.011\n",
      "zone id: 2, n_pilots: 13, perf: 0.937\n",
      "zone id: 2, n_pilots: 26, perf: 0.938\n",
      "zone id: 2, n_pilots: 38, perf: 0.938\n",
      "zone id: 2, n_pilots: 51, perf: 0.937\n",
      "zone id: 2, n_pilots: 64, perf: 0.940\n",
      "zone id: 2, n_pilots: 77, perf: 0.943\n",
      "zone id: 2, n_pilots: 90, perf: 0.939\n",
      "zone id: 2, n_pilots: 102, perf: 0.939\n",
      "zone id: 2, n_pilots: 115, perf: 0.941\n",
      "zone id: 2, n_pilots: 128, perf: 0.955\n",
      "zone id: 3, n_pilots: 1, perf: 0.010\n",
      "zone id: 3, n_pilots: 13, perf: 0.941\n",
      "zone id: 3, n_pilots: 26, perf: 0.944\n",
      "zone id: 3, n_pilots: 38, perf: 0.943\n",
      "zone id: 3, n_pilots: 51, perf: 0.944\n",
      "zone id: 3, n_pilots: 64, perf: 0.944\n",
      "zone id: 3, n_pilots: 77, perf: 0.944\n",
      "zone id: 3, n_pilots: 90, perf: 0.947\n",
      "zone id: 3, n_pilots: 102, perf: 0.947\n",
      "zone id: 3, n_pilots: 115, perf: 0.946\n",
      "zone id: 3, n_pilots: 128, perf: 0.954\n",
      "zone id: 4, n_pilots: 1, perf: 0.014\n",
      "zone id: 4, n_pilots: 13, perf: 0.921\n",
      "zone id: 4, n_pilots: 26, perf: 0.924\n",
      "zone id: 4, n_pilots: 38, perf: 0.925\n",
      "zone id: 4, n_pilots: 51, perf: 0.928\n",
      "zone id: 4, n_pilots: 64, perf: 0.929\n",
      "zone id: 4, n_pilots: 77, perf: 0.930\n",
      "zone id: 4, n_pilots: 90, perf: 0.933\n",
      "zone id: 4, n_pilots: 102, perf: 0.932\n",
      "zone id: 4, n_pilots: 115, perf: 0.938\n",
      "zone id: 4, n_pilots: 128, perf: 0.953\n",
      "zone id: 5, n_pilots: 1, perf: 0.045\n",
      "zone id: 5, n_pilots: 13, perf: 0.927\n",
      "zone id: 5, n_pilots: 26, perf: 0.937\n",
      "zone id: 5, n_pilots: 38, perf: 0.940\n",
      "zone id: 5, n_pilots: 51, perf: 0.943\n",
      "zone id: 5, n_pilots: 64, perf: 0.942\n",
      "zone id: 5, n_pilots: 77, perf: 0.943\n",
      "zone id: 5, n_pilots: 90, perf: 0.946\n",
      "zone id: 5, n_pilots: 102, perf: 0.945\n",
      "zone id: 5, n_pilots: 115, perf: 0.947\n",
      "zone id: 5, n_pilots: 128, perf: 0.953\n",
      "zone id: 6, n_pilots: 1, perf: 0.051\n",
      "zone id: 6, n_pilots: 13, perf: 0.940\n",
      "zone id: 6, n_pilots: 26, perf: 0.945\n",
      "zone id: 6, n_pilots: 38, perf: 0.943\n",
      "zone id: 6, n_pilots: 51, perf: 0.945\n",
      "zone id: 6, n_pilots: 64, perf: 0.946\n",
      "zone id: 6, n_pilots: 77, perf: 0.945\n",
      "zone id: 6, n_pilots: 90, perf: 0.946\n",
      "zone id: 6, n_pilots: 102, perf: 0.947\n",
      "zone id: 6, n_pilots: 115, perf: 0.948\n",
      "zone id: 6, n_pilots: 128, perf: 0.955\n",
      "zone id: 7, n_pilots: 1, perf: 0.048\n",
      "zone id: 7, n_pilots: 13, perf: 0.943\n",
      "zone id: 7, n_pilots: 26, perf: 0.950\n",
      "zone id: 7, n_pilots: 38, perf: 0.946\n",
      "zone id: 7, n_pilots: 51, perf: 0.944\n",
      "zone id: 7, n_pilots: 64, perf: 0.944\n",
      "zone id: 7, n_pilots: 77, perf: 0.945\n",
      "zone id: 7, n_pilots: 90, perf: 0.946\n",
      "zone id: 7, n_pilots: 102, perf: 0.947\n",
      "zone id: 7, n_pilots: 115, perf: 0.948\n",
      "zone id: 7, n_pilots: 128, perf: 0.953\n",
      "zone id: 8, n_pilots: 1, perf: 0.022\n",
      "zone id: 8, n_pilots: 13, perf: 0.916\n",
      "zone id: 8, n_pilots: 26, perf: 0.924\n",
      "zone id: 8, n_pilots: 38, perf: 0.928\n",
      "zone id: 8, n_pilots: 51, perf: 0.928\n",
      "zone id: 8, n_pilots: 64, perf: 0.931\n",
      "zone id: 8, n_pilots: 77, perf: 0.931\n",
      "zone id: 8, n_pilots: 90, perf: 0.933\n",
      "zone id: 8, n_pilots: 102, perf: 0.932\n",
      "zone id: 8, n_pilots: 115, perf: 0.937\n",
      "zone id: 8, n_pilots: 128, perf: 0.954\n",
      "zone id: 9, n_pilots: 1, perf: 0.006\n",
      "zone id: 9, n_pilots: 13, perf: 0.423\n",
      "zone id: 9, n_pilots: 26, perf: 0.878\n",
      "zone id: 9, n_pilots: 38, perf: 0.886\n",
      "zone id: 9, n_pilots: 51, perf: 0.908\n",
      "zone id: 9, n_pilots: 64, perf: 0.918\n",
      "zone id: 9, n_pilots: 77, perf: 0.923\n",
      "zone id: 9, n_pilots: 90, perf: 0.931\n",
      "zone id: 9, n_pilots: 102, perf: 0.930\n",
      "zone id: 9, n_pilots: 115, perf: 0.938\n",
      "zone id: 9, n_pilots: 128, perf: 0.954\n",
      "zone id: 10, n_pilots: 1, perf: 0.050\n",
      "zone id: 10, n_pilots: 13, perf: 0.886\n",
      "zone id: 10, n_pilots: 26, perf: 0.889\n",
      "zone id: 10, n_pilots: 38, perf: 0.895\n",
      "zone id: 10, n_pilots: 51, perf: 0.899\n",
      "zone id: 10, n_pilots: 64, perf: 0.901\n",
      "zone id: 10, n_pilots: 77, perf: 0.904\n",
      "zone id: 10, n_pilots: 90, perf: 0.905\n",
      "zone id: 10, n_pilots: 102, perf: 0.909\n",
      "zone id: 10, n_pilots: 115, perf: 0.915\n",
      "zone id: 10, n_pilots: 128, perf: 0.954\n",
      "zone id: 11, n_pilots: 1, perf: 0.039\n",
      "zone id: 11, n_pilots: 13, perf: 0.939\n",
      "zone id: 11, n_pilots: 26, perf: 0.946\n",
      "zone id: 11, n_pilots: 38, perf: 0.944\n",
      "zone id: 11, n_pilots: 51, perf: 0.946\n",
      "zone id: 11, n_pilots: 64, perf: 0.946\n",
      "zone id: 11, n_pilots: 77, perf: 0.946\n",
      "zone id: 11, n_pilots: 90, perf: 0.947\n",
      "zone id: 11, n_pilots: 102, perf: 0.948\n",
      "zone id: 11, n_pilots: 115, perf: 0.948\n",
      "zone id: 11, n_pilots: 128, perf: 0.954\n",
      "\n",
      "\n",
      "trial: 0\n",
      "dataset type: Random DFT-based Pilots\n",
      "Number of users: 70\n",
      "Adjusted parameters: n_areas=12, n_kmeans_clusters=35\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     32\u001b[39m     n_kmeans_clusters = \u001b[32m1\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (dataset_idx == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m subspace_coeff == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m dataset_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mRandom DFT-based Pilots\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     dt_subspaces, rw_subspaces, kmeans_centroids, kmeans_labels = k_means(\n\u001b[32m     37\u001b[39m         enabled_idxs, \n\u001b[32m     38\u001b[39m         imperfect_dataset, \n\u001b[32m     39\u001b[39m         dataset_rw,\n\u001b[32m     40\u001b[39m         pos[:,:\u001b[32m3\u001b[39m], \n\u001b[32m     41\u001b[39m         los_status,\n\u001b[32m     42\u001b[39m         best_beam,\n\u001b[32m     43\u001b[39m         bs_pos, \n\u001b[32m     44\u001b[39m         pos_coeff,  \n\u001b[32m     45\u001b[39m         los_coeff_kmeans, \n\u001b[32m     46\u001b[39m         beam_coeff_kmeans,  \n\u001b[32m     47\u001b[39m         percent=\u001b[32m.95\u001b[39m,  \n\u001b[32m     48\u001b[39m         n_kmeans_clusters=n_kmeans_clusters, \n\u001b[32m     49\u001b[39m         k_predefined2=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     50\u001b[39m         seed=trial\n\u001b[32m     51\u001b[39m     )\n\u001b[32m     53\u001b[39m     areas, area_lens = k_med(\n\u001b[32m     54\u001b[39m         dt_subspaces, \n\u001b[32m     55\u001b[39m         pos_coeff, \n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m         seed=trial\n\u001b[32m     64\u001b[39m     )\n\u001b[32m     66\u001b[39m avg_nmse_ss = subspace_estimation(\n\u001b[32m     67\u001b[39m     imperfect_dataset, \n\u001b[32m     68\u001b[39m     dataset_rw, \n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m     seed=trial\n\u001b[32m     78\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Sadjad\\Git\\Digital-twin-aided-channel-estimation\\utils.py:259\u001b[39m, in \u001b[36mk_means\u001b[39m\u001b[34m(enabled_idxs, dataset_dt, dataset_rw, pos, los_status, best_beam, bs_pos, pos_coeff, los_coeff_kmeans, beam_coeff_kmeans, percent, n_kmeans_clusters, k_predefined2, seed)\u001b[39m\n\u001b[32m    253\u001b[39m stacked_channels_rw = torch.cat([dataset_rw[i].unsqueeze(\u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m cluster_indices], dim=\u001b[32m0\u001b[39m)\n\u001b[32m    255\u001b[39m dominant_subspace, k_percent = find_subspace_90_percent(stacked_channels, \n\u001b[32m    256\u001b[39m                                                         percent=percent, \n\u001b[32m    257\u001b[39m                                                         k_predefined_2=k_predefined2) \n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m dominant_subspace_rw, k_percent_rw = find_subspace_90_percent(stacked_channels_rw, \n\u001b[32m    260\u001b[39m                                                               percent=percent, \n\u001b[32m    261\u001b[39m                                                               k_predefined_2=k_predefined2) \n\u001b[32m    263\u001b[39m p_angles, grassmann_dist = plot_subspace(dominant_subspace_rw, dominant_subspace)\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# print(f'grassmann dist (DT,RW) fine clusters: {grassmann_dist}')\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Sadjad\\Git\\Digital-twin-aided-channel-estimation\\utils.py:36\u001b[39m, in \u001b[36mfind_subspace_90_percent\u001b[39m\u001b[34m(data, percent, k_predefined_2)\u001b[39m\n\u001b[32m     33\u001b[39m data_mean = torch.mean(data)\n\u001b[32m     34\u001b[39m dt_covariance = (data-data_mean).T.conj() @ (data-data_mean) / (data.size(\u001b[32m0\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m U, S, Vh = torch.linalg.svd(dt_covariance, full_matrices=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     38\u001b[39m total_power = torch.sum(S)\n\u001b[32m     39\u001b[39m explained_power = torch.cumsum(S, dim=\u001b[32m0\u001b[39m) / total_power\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trials = 200\n",
    "datasets = [\n",
    "    \"Real-World\",  \n",
    "    \"Digital Twin\",  \n",
    "    \"Random DFT-based Pilots\"\n",
    "]\n",
    "dft_based = True  \n",
    "n_pilots = np.array([1, 13, 26, 38, 51, 64, 77, 90, 102, 115, 128])\n",
    "snr_db = 10 \n",
    "loss_func = [\"nmse\", \"cosine\", \"throughput\"][1]\n",
    "ss_nmse = np.zeros((len(datasets), len(n_pilots), trials))\n",
    "\n",
    "for trial in range(trials):\n",
    "    \n",
    "    for dataset_idx, dataset_type in enumerate(datasets):\n",
    "        \n",
    "        print(f\"\\n\\ntrial: {trial}\\ndataset type: {dataset_type}\")\n",
    "        print(f\"Number of users: {n_users}\")\n",
    "  \n",
    "        n_areas = min(12, n_users // 4)  # Ensure areas <= samples/4\n",
    "        n_kmeans_clusters = min(80, n_users // 2)  # Ensure clusters <= samples/2\n",
    "        \n",
    "        print(f\"Adjusted parameters: n_areas={n_areas}, n_kmeans_clusters={n_kmeans_clusters}\") \n",
    "        \n",
    "        if dataset_type in [\"Digital Twin\"]:\n",
    "            imperfect_dataset = dataset_dt\n",
    "        elif dataset_type == \"Real-World\":\n",
    "            imperfect_dataset = dataset_rw\n",
    "        elif dataset_type == \"Random DFT-based Pilots\":\n",
    "            imperfect_dataset = dataset_rw\n",
    "            n_areas = 1\n",
    "            n_kmeans_clusters = 1\n",
    "        \n",
    "        if (dataset_idx == 0 and subspace_coeff == 0) or dataset_type in [\"Random DFT-based Pilots\"]:\n",
    "            \n",
    "            dt_subspaces, rw_subspaces, kmeans_centroids, kmeans_labels = k_means(\n",
    "                enabled_idxs, \n",
    "                imperfect_dataset, \n",
    "                dataset_rw,\n",
    "                pos[:,:3], \n",
    "                los_status,\n",
    "                best_beam,\n",
    "                bs_pos, \n",
    "                pos_coeff,  \n",
    "                los_coeff_kmeans, \n",
    "                beam_coeff_kmeans,  \n",
    "                percent=.95,  \n",
    "                n_kmeans_clusters=n_kmeans_clusters, \n",
    "                k_predefined2=None,\n",
    "                seed=trial\n",
    "            )\n",
    "            \n",
    "            areas, area_lens = k_med(\n",
    "                dt_subspaces, \n",
    "                pos_coeff, \n",
    "                subspace_coeff, \n",
    "                kmeans_centroids, \n",
    "                n_areas, \n",
    "                kmeans_labels,\n",
    "                pos[:,:3],\n",
    "                enabled_idxs,\n",
    "                bs_pos,\n",
    "                seed=trial\n",
    "            )\n",
    "        \n",
    "        avg_nmse_ss = subspace_estimation(\n",
    "            imperfect_dataset, \n",
    "            dataset_rw, \n",
    "            areas, \n",
    "            area_lens, \n",
    "            codebook,\n",
    "            n_pilots,\n",
    "            dataset_type,\n",
    "            snr_db=snr_db,\n",
    "            loss_func=loss_func,\n",
    "            dft_based=dft_based,\n",
    "            seed=trial\n",
    "        )\n",
    "        \n",
    "        ss_nmse[dataset_idx, :, trial] = todB(avg_nmse_ss).squeeze() if loss_func == \"nmse\" else avg_nmse_ss.squeeze()\n",
    "\n",
    "    # FIGURE     \n",
    "    plot_perf_vs_pilots(datasets, ss_nmse, n_pilots, n_beams, trial, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 3: CDF (With Calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 200\n",
    "datasets = [\n",
    "    \"Real-World\",  \n",
    "    \"Digital Twin\",  \n",
    "    \"RL-Calibrated Digital Twin\",  \n",
    "    \"Random DFT-based Pilots\",  \n",
    "    \"RL-Calibrated Random Pilots\"\n",
    "]\n",
    "dft_based = True  \n",
    "n_pilots = [26]\n",
    "snr_db = 10 \n",
    "loss_func = [\"nmse\", \"cosine\", \"throughput\"][1]\n",
    "ss_nmse = np.zeros((len(datasets), len(n_pilots), trials))\n",
    "\n",
    "for trial in range(trials):\n",
    "    \n",
    "    for dataset_idx, dataset_type in enumerate(datasets):\n",
    "        \n",
    "        print(f\"\\n\\ntrial: {trial}\\ndataset type: {dataset_type}\")\n",
    "        print(f\"Number of users: {n_users}\")\n",
    "        \n",
    "        n_areas = min(12, n_users // 4)  # Ensure areas <= samples/4\n",
    "        n_kmeans_clusters = min(80, n_users // 2)  # Ensure clusters <= samples/2\n",
    "        \n",
    "        print(f\"Adjusted parameters: n_areas={n_areas}, n_kmeans_clusters={n_kmeans_clusters}\") \n",
    "        \n",
    "        if dataset_type in [\"Digital Twin\", \"RL-Calibrated Digital Twin\"]:\n",
    "            imperfect_dataset = dataset_dt\n",
    "        elif dataset_type == \"Real-World\":\n",
    "            imperfect_dataset = dataset_rw\n",
    "        elif dataset_type in [\"Random DFT-based Pilots\", \"RL-Calibrated Random Pilots\"]:\n",
    "            imperfect_dataset = dataset_rw\n",
    "            n_areas = 1\n",
    "            n_kmeans_clusters = 1\n",
    "        \n",
    "        if (dataset_idx == 0 and subspace_coeff == 0) or dataset_type in [\"Random DFT-based Pilots\"]:\n",
    "            \n",
    "            dt_subspaces, rw_subspaces, kmeans_centroids, kmeans_labels = k_means(\n",
    "                enabled_idxs, \n",
    "                imperfect_dataset, \n",
    "                dataset_rw,\n",
    "                pos[:,:3], \n",
    "                los_status,\n",
    "                best_beam,\n",
    "                bs_pos, \n",
    "                pos_coeff,  \n",
    "                los_coeff_kmeans, \n",
    "                beam_coeff_kmeans,  \n",
    "                percent=.95,  \n",
    "                n_kmeans_clusters=n_kmeans_clusters, \n",
    "                k_predefined2=None,\n",
    "                seed=trial\n",
    "            )\n",
    "            \n",
    "            areas, area_lens = k_med(\n",
    "                dt_subspaces, \n",
    "                pos_coeff, \n",
    "                subspace_coeff, \n",
    "                kmeans_centroids, \n",
    "                n_areas, \n",
    "                kmeans_labels,\n",
    "                pos[:,:3],\n",
    "                enabled_idxs,\n",
    "                bs_pos,\n",
    "                seed=trial\n",
    "            )\n",
    "    \n",
    "        if dataset_type in [\"Real-World\", \"Random DFT-based Pilots\", \"Digital Twin\"]:\n",
    "            \n",
    "            avg_nmse_ss = subspace_estimation(\n",
    "                imperfect_dataset, \n",
    "                dataset_rw, \n",
    "                areas, \n",
    "                area_lens, \n",
    "                codebook,\n",
    "                n_pilots,\n",
    "                dataset_type,\n",
    "                snr_db=snr_db,\n",
    "                loss_func=loss_func,\n",
    "                dft_based=dft_based,\n",
    "                seed=trial\n",
    "            )\n",
    "            \n",
    "        elif dataset_type in [\"RL-Calibrated Digital Twin\", \"RL-Calibrated Random Pilots\"]:\n",
    "            \n",
    "            avg_nmse_ss = subspace_estimation_drl(\n",
    "                imperfect_dataset, \n",
    "                dataset_rw, \n",
    "                areas, \n",
    "                area_lens, \n",
    "                codebook, \n",
    "                dataset_type,\n",
    "                n_pilots=n_pilots[0], \n",
    "                n_episodes=300, \n",
    "                snr_db=snr_db, \n",
    "                loss_func=loss_func, \n",
    "                seed=trial\n",
    "            )\n",
    "        \n",
    "        ss_nmse[dataset_idx, :, trial] = todB(avg_nmse_ss) if loss_func == \"nmse\" else avg_nmse_ss\n",
    "        \n",
    "    # CDF PLOT\n",
    "    plot_smooth_cdf(datasets, ss_nmse, trial=trial, loss_func=loss_func, n=13, r=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
